[global]
logs = dumps/
path = dumps/model
model = baseline

[baseline]
vocabsize = 10000
wvecsize = 100
depth = 4
steps = 20
batch = 50
deepness = 2
classes = 3
mslrate = 1e-2
msdrate = 0.99
msdstep = 1000
msoptim = AdamOptimizer
celrate = 1e-2
cedrate = 0.99
cedstep = 1000
ceoptim = AdamOptimizer

[attention]
vocabsize = 10000
wvecsize = 100
depth = 4
steps = 20
memory = 2
batch = 50
deepness = 2
classes = 3
mslrate = 1e-2
msdrate = 0.99
msdstep = 1000
msoptim = AdamOptimizer
celrate = 1e-2
cedrate = 0.99
cedstep = 1000
ceoptim = AdamOptimizer
